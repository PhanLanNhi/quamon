{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3abebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight = 1.15\n",
      "\n",
      "=== XGBoost Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6073    0.6593    0.6322      6759\n",
      "           1     0.5673    0.5118    0.5381      5901\n",
      "\n",
      "    accuracy                         0.5905     12660\n",
      "   macro avg     0.5873    0.5855    0.5852     12660\n",
      "weighted avg     0.5887    0.5905    0.5884     12660\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4456 2303]\n",
      " [2881 3020]]\n",
      "Accuracy: 0.590521327014218\n",
      "Macro F1: 0.5851843342019655\n",
      "\n",
      "Top 15 XGBoost Feature Importances:\n",
      "                           feature  importance\n",
      "80                   fault_rate_50    0.048574\n",
      "7                    Anomaly_Score    0.025070\n",
      "5                     FFT_Feature1    0.023519\n",
      "6                     FFT_Feature2    0.021824\n",
      "1             Normalized_Vibration    0.021146\n",
      "2              Normalized_Pressure    0.013962\n",
      "3               Normalized_Voltage    0.012937\n",
      "0                  Normalized_Temp    0.012774\n",
      "25      Normalized_Vibration_delta    0.012427\n",
      "49    Normalized_Current_rollstd15    0.012028\n",
      "68         FFT_Feature2_rollmean30    0.011924\n",
      "74          Anomaly_Score_rollstd7    0.011863\n",
      "65           FFT_Feature2_rollstd7    0.011769\n",
      "70              FFT_Feature2_delta    0.011756\n",
      "22  Normalized_Vibration_rollstd15    0.011732\n",
      "[LightGBM] [Info] Number of positive: 23602, number of negative: 27034\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20576\n",
      "[LightGBM] [Info] Number of data points in the train set: 50636, number of used features: 81\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466111 -> initscore=-0.135764\n",
      "[LightGBM] [Info] Start training from score -0.135764\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "=== LightGBM Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6142    0.6789    0.6450      6759\n",
      "           1     0.5818    0.5116    0.5445      5901\n",
      "\n",
      "    accuracy                         0.6009     12660\n",
      "   macro avg     0.5980    0.5953    0.5947     12660\n",
      "weighted avg     0.5991    0.6009    0.5981     12660\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4589 2170]\n",
      " [2882 3019]]\n",
      "Accuracy: 0.6009478672985782\n",
      "Macro F1: 0.5947149337782547\n",
      "\n",
      "Top 15 LightGBM Feature Importances:\n",
      "                          feature  importance\n",
      "80                  fault_rate_50         314\n",
      "6                    FFT_Feature2         264\n",
      "7                   Anomaly_Score         253\n",
      "1            Normalized_Vibration         243\n",
      "5                    FFT_Feature1         205\n",
      "0                 Normalized_Temp         187\n",
      "2             Normalized_Pressure         182\n",
      "4              Normalized_Current         176\n",
      "16          Normalized_Temp_delta         171\n",
      "52       Normalized_Current_delta         168\n",
      "53         FFT_Feature1_rollmean3         167\n",
      "3              Normalized_Voltage         167\n",
      "39  Normalized_Voltage_rollmean15         167\n",
      "61             FFT_Feature1_delta         157\n",
      "9        Normalized_Temp_rollstd3         156\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === 1. Đọc dữ liệu và tạo feature engineering ===\n",
    "df = pd.read_csv(\"D:/dow/project/data/full_dataset_with_gan.csv\")\n",
    "base = [\n",
    "    'Normalized_Temp', 'Normalized_Vibration', 'Normalized_Pressure',\n",
    "    'Normalized_Voltage', 'Normalized_Current',\n",
    "    'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score'\n",
    "]\n",
    "df = df.sort_values(['Sensor_ID', 'Year', 'Month', 'Day', 'Hour', 'Minute'])\n",
    "\n",
    "for col in base:\n",
    "    for w in [3, 7, 15, 30]:\n",
    "        df[f'{col}_rollmean{w}'] = df.groupby('Sensor_ID')[col].transform(lambda x: x.rolling(w, min_periods=1).mean())\n",
    "        df[f'{col}_rollstd{w}']  = df.groupby('Sensor_ID')[col].transform(lambda x: x.rolling(w, min_periods=1).std().fillna(0))\n",
    "    df[f'{col}_delta'] = df.groupby('Sensor_ID')[col].diff().fillna(0)\n",
    "df['fault_rate_50'] = df.groupby('Sensor_ID')['Fault_Status'].transform(lambda x: x.rolling(50, min_periods=1).mean())\n",
    "\n",
    "drop_cols = ['Sensor_ID', 'Fault_Status', 'Fault_Type', 'Year','Month','Day','Hour','Minute']\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "# === 2. Chia train/test ===\n",
    "X = df[feature_cols].fillna(0)\n",
    "y = df['Fault_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# === 3. Tính scale_pos_weight cho dữ liệu mất cân bằng ===\n",
    "n0 = (y_train == 0).sum()\n",
    "n1 = (y_train == 1).sum()\n",
    "scale_pos_weight = n0 / n1\n",
    "print(\"scale_pos_weight =\", round(scale_pos_weight, 2))\n",
    "\n",
    "# === 4. Tạo thư mục lưu kết quả ===\n",
    "result_dir = r\"D:/dow/project/evaluation/feature\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# === 5. Huấn luyện và đánh giá XGBoost ===\n",
    "model_xgb = XGBClassifier(\n",
    "    use_label_encoder=False, eval_metric='logloss', random_state=42, \n",
    "    n_estimators=400, learning_rate=0.13, max_depth=6, subsample=0.93, \n",
    "    colsample_bytree=0.71, scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Báo cáo đánh giá XGBoost (in ra console)\n",
    "print(\"\\n=== XGBoost Evaluation ===\")\n",
    "print(classification_report(y_test, y_pred_xgb, digits=4))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred_xgb, average='macro'))\n",
    "\n",
    "# Báo cáo đánh giá XGBoost (lưu file csv)\n",
    "xgb_report_dict = classification_report(y_test, y_pred_xgb, digits=4, output_dict=True)\n",
    "xgb_report_df = pd.DataFrame(xgb_report_dict).transpose()\n",
    "xgb_report_df.to_csv(os.path.join(result_dir, \"xgb_feature_report.csv\"))\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_xgb)).to_csv(\n",
    "    os.path.join(result_dir, \"xgb_feature_confusion_matrix.csv\"), index=False, header=False)\n",
    "\n",
    "# Lưu model XGBoost\n",
    "joblib.dump(model_xgb, os.path.join(result_dir, \"xgb_feature_model.pkl\"))\n",
    "\n",
    "# Feature importance XGBoost (vừa in vừa lưu ảnh/csv)\n",
    "xgb_fi_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": model_xgb.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 XGBoost Feature Importances:\")\n",
    "print(xgb_fi_df.head(15))\n",
    "xgb_fi_df.to_csv(os.path.join(result_dir, \"xgb_feature_importance.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7, 9))\n",
    "plt.barh(xgb_fi_df['feature'].head(20)[::-1], xgb_fi_df['importance'].head(20)[::-1])\n",
    "plt.title(\"XGBoost Feature Importances (Top 20)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(result_dir, \"xgb_feature_importance.png\"))\n",
    "plt.close()\n",
    "\n",
    "# === 6. Huấn luyện và đánh giá LightGBM ===\n",
    "model_lgbm = LGBMClassifier(\n",
    "    random_state=42, n_estimators=400, learning_rate=0.13, max_depth=6,\n",
    "    subsample=0.93, colsample_bytree=0.71, scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "model_lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm = model_lgbm.predict(X_test)\n",
    "\n",
    "print(\"\\n=== LightGBM Evaluation ===\")\n",
    "print(classification_report(y_test, y_pred_lgbm, digits=4))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred_lgbm, average='macro'))\n",
    "\n",
    "lgbm_report_dict = classification_report(y_test, y_pred_lgbm, digits=4, output_dict=True)\n",
    "lgbm_report_df = pd.DataFrame(lgbm_report_dict).transpose()\n",
    "lgbm_report_df.to_csv(os.path.join(result_dir, \"lgbm_feature_report.csv\"))\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_lgbm)).to_csv(\n",
    "    os.path.join(result_dir, \"lgbm_feature_confusion_matrix.csv\"), index=False, header=False)\n",
    "\n",
    "joblib.dump(model_lgbm, os.path.join(result_dir, \"lgbm_feature_model.pkl\"))\n",
    "\n",
    "lgbm_fi_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": model_lgbm.feature_importances_\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 LightGBM Feature Importances:\")\n",
    "print(lgbm_fi_df.head(15))\n",
    "lgbm_fi_df.to_csv(os.path.join(result_dir, \"lgbm_feature_importance.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7, 9))\n",
    "plt.barh(lgbm_fi_df['feature'].head(20)[::-1], lgbm_fi_df['importance'].head(20)[::-1])\n",
    "plt.title(\"LightGBM Feature Importances (Top 20)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(result_dir, \"lgbm_feature_importance.png\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938141cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063e234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
