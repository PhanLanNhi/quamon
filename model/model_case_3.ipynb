{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c2776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ------------------------- 1. Đọc và xử lý dữ liệu -------------------------\n",
    "df = pd.read_csv(r'D:\\dow\\project\\data\\full_dataset_with_gan.csv')\n",
    "\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    base = [\n",
    "        'Normalized_Temp', 'Normalized_Vibration', 'Normalized_Pressure',\n",
    "        'Normalized_Voltage', 'Normalized_Current',\n",
    "        'FFT_Feature1', 'FFT_Feature2', 'Anomaly_Score'\n",
    "    ]\n",
    "    df = df.sort_values(['Sensor_ID', 'Year', 'Month', 'Day', 'Hour', 'Minute'])\n",
    "    for col in base:\n",
    "        for w in [3, 7, 15]:\n",
    "            df[f'{col}_rollmean{w}'] = df.groupby('Sensor_ID')[col].transform(lambda x: x.rolling(w, min_periods=1).mean())\n",
    "            df[f'{col}_rollstd{w}'] = df.groupby('Sensor_ID')[col].transform(lambda x: x.rolling(w, min_periods=1).std().fillna(0))\n",
    "    df['Temp_Vibration_ratio'] = df['Normalized_Temp'] / (df['Normalized_Vibration'] + 1e-5)\n",
    "    df['Delta_Current'] = df['Normalized_Current'].diff().fillna(0)\n",
    "    return df\n",
    "\n",
    "df = add_features(df)\n",
    "drop_cols = ['Sensor_ID', 'Fault_Status', 'Fault_Type', 'Year','Month','Day','Hour','Minute']\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "# ------------------------- 2. Hàm đánh giá -------------------------\n",
    "def print_metrics(y_true, y_pred, name):\n",
    "    print(f\"\\n=== [{name}] ===\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Macro F1:\", f1_score(y_true, y_pred, average='macro'))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "\n",
    "# ------------------------- 3. Hàm chạy từng kịch bản -------------------------\n",
    "def run_case(case_name, X_train, y_train, X_test, y_test):\n",
    "    print(f\"\\n===== {case_name} =====\")\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    print_metrics(y_test, y_pred_xgb, \"XGBoost\")\n",
    "\n",
    "    # LightGBM\n",
    "    lgbm = LGBMClassifier(random_state=42)\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    y_pred_lgbm = lgbm.predict(X_test)\n",
    "    print_metrics(y_test, y_pred_lgbm, \"LightGBM\")\n",
    "\n",
    "# ------------------------- 4. Hàm chia theo thiết bị (phụ thuộc) -------------------------\n",
    "def split_by_device(df, test_size=0.15, val_size=0.15):\n",
    "    train_list, test_list, val_list = [], [], []\n",
    "    for device in df['Sensor_ID'].unique():\n",
    "        sub = df[df['Sensor_ID'] == device]\n",
    "        train_sub, test_val_sub = train_test_split(sub, test_size=(test_size + val_size), random_state=42, shuffle=True)\n",
    "        test_sub, val_sub = train_test_split(test_val_sub, test_size=val_size / (test_size + val_size), random_state=42)\n",
    "        train_list.append(train_sub)\n",
    "        test_list.append(test_sub)\n",
    "        val_list.append(val_sub)\n",
    "    train = pd.concat(train_list)\n",
    "    test = pd.concat(test_list)\n",
    "    val = pd.concat(val_list)\n",
    "    return train, test, val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e0997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CASE 1: Dependent split per device =====\n",
      "\n",
      "=== [XGBoost] ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5677    0.7200    0.6348      4964\n",
      "           1     0.5643    0.3981    0.4668      4522\n",
      "\n",
      "    accuracy                         0.5665      9486\n",
      "   macro avg     0.5660    0.5590    0.5508      9486\n",
      "weighted avg     0.5660    0.5665    0.5547      9486\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3574 1390]\n",
      " [2722 1800]]\n",
      "Accuracy: 0.5665190807505798\n",
      "Macro F1: 0.5508092391825063\n",
      "Precision: 0.5642633228840125\n",
      "Recall: 0.3980539584254755\n",
      "[LightGBM] [Info] Number of positive: 20482, number of negative: 23784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14790\n",
      "[LightGBM] [Info] Number of data points in the train set: 44266, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.462703 -> initscore=-0.149467\n",
      "[LightGBM] [Info] Start training from score -0.149467\n",
      "\n",
      "=== [LightGBM] ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5654    0.8624    0.6830      4964\n",
      "           1     0.6433    0.2724    0.3828      4522\n",
      "\n",
      "    accuracy                         0.5812      9486\n",
      "   macro avg     0.6044    0.5674    0.5329      9486\n",
      "weighted avg     0.6026    0.5812    0.5399      9486\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4281  683]\n",
      " [3290 1232]]\n",
      "Accuracy: 0.5811722538477757\n",
      "Macro F1: 0.5329172398378218\n",
      "Precision: 0.6433420365535248\n",
      "Recall: 0.2724458204334365\n"
     ]
    }
   ],
   "source": [
    "# ====================== 5. Các kịch bản chia dữ liệu ======================\n",
    "\n",
    "## CASE 1: Dependent split per device\n",
    "train, test, val = split_by_device(df)\n",
    "X_train, y_train = train[feature_cols], train['Fault_Status']\n",
    "X_test, y_test = test[feature_cols], test['Fault_Status']\n",
    "run_case(\"CASE 1: Dependent split per device\", X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16734060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CASE 2: Independent split per device =====\n",
      "\n",
      "=== [XGBoost] ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5654    0.6995    0.6253      5015\n",
      "           1     0.5419    0.3980    0.4589      4480\n",
      "\n",
      "    accuracy                         0.5572      9495\n",
      "   macro avg     0.5536    0.5487    0.5421      9495\n",
      "weighted avg     0.5543    0.5572    0.5468      9495\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3508 1507]\n",
      " [2697 1783]]\n",
      "Accuracy: 0.5572406529752502\n",
      "Macro F1: 0.5421283009518304\n",
      "Precision: 0.5419452887537994\n",
      "Recall: 0.39799107142857143\n",
      "[LightGBM] [Info] Number of positive: 20646, number of negative: 23505\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14790\n",
      "[LightGBM] [Info] Number of data points in the train set: 44151, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.467622 -> initscore=-0.129692\n",
      "[LightGBM] [Info] Start training from score -0.129692\n",
      "\n",
      "=== [LightGBM] ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5714    0.8231    0.6746      5015\n",
      "           1     0.6094    0.3089    0.4100      4480\n",
      "\n",
      "    accuracy                         0.5805      9495\n",
      "   macro avg     0.5904    0.5660    0.5423      9495\n",
      "weighted avg     0.5894    0.5805    0.5497      9495\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4128  887]\n",
      " [3096 1384]]\n",
      "Accuracy: 0.5805160610847815\n",
      "Macro F1: 0.5422891233962924\n",
      "Precision: 0.6094231616028182\n",
      "Recall: 0.30892857142857144\n"
     ]
    }
   ],
   "source": [
    "## CASE 2: Independent split per device\n",
    "unique_sensors = df['Sensor_ID'].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_sensors)\n",
    "n = len(unique_sensors)\n",
    "train_sensor = unique_sensors[:int(0.7*n)]\n",
    "test_sensor = unique_sensors[int(0.7*n):int(0.85*n)]\n",
    "train = df[df['Sensor_ID'].isin(train_sensor)]\n",
    "test = df[df['Sensor_ID'].isin(test_sensor)]\n",
    "X_train, y_train = train[feature_cols], train['Fault_Status']\n",
    "X_test, y_test = test[feature_cols], test['Fault_Status']\n",
    "run_case(\"CASE 2: Independent split per device\", X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d763f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CASE 3: Random split all data =====\n",
      "\n",
      "=== [XGBoost] ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5695    0.7201    0.6360     10055\n",
      "           1     0.5515    0.3873    0.4550      8934\n",
      "\n",
      "    accuracy                         0.5635     18989\n",
      "   macro avg     0.5605    0.5537    0.5455     18989\n",
      "weighted avg     0.5610    0.5635    0.5509     18989\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7241 2814]\n",
      " [5474 3460]]\n",
      "Accuracy: 0.5635367844541577\n",
      "Macro F1: 0.5455179843167859\n",
      "Precision: 0.55148230793752\n",
      "Recall: 0.38728453100514887\n",
      "[LightGBM] [Info] Number of positive: 20569, number of negative: 23738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14790\n",
      "[LightGBM] [Info] Number of data points in the train set: 44307, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464238 -> initscore=-0.143292\n",
      "[LightGBM] [Info] Start training from score -0.143292\n",
      "\n",
      "=== [LightGBM] ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5705    0.8492    0.6825     10055\n",
      "           1     0.6231    0.2805    0.3868      8934\n",
      "\n",
      "    accuracy                         0.5817     18989\n",
      "   macro avg     0.5968    0.5649    0.5347     18989\n",
      "weighted avg     0.5952    0.5817    0.5434     18989\n",
      "\n",
      "Confusion Matrix:\n",
      " [[8539 1516]\n",
      " [6428 2506]]\n",
      "Accuracy: 0.5816525356785507\n",
      "Macro F1: 0.5346835877357842\n",
      "Precision: 0.6230730979612134\n",
      "Recall: 0.2805014551152899\n"
     ]
    }
   ],
   "source": [
    "## CASE 3: Random split all data\n",
    "X = df[feature_cols]\n",
    "y = df['Fault_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "run_case(\"CASE 3: Random split all data\", X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cb5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe36c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
